\subsection{In-house Algorithmic Profiling}
\label{sec:in-house}

During in-house testing, \Tool profiles the whole program, 
since runtime overhead is less of a concern. 
Existing testing inputs can be used to launch \Tool, 
and testing input generation techniques~\cite{KLEE,dart,s2e} 
can also be utilized to create more inputs.
For testing inputs with repetitive patterns, 
developer can change these inputs by themselves 
and create inputs with the same functionality but different sizes. 
\Tool automatically merges input and cost information 
for the same code constructs
collected from multiple runs with different inputs and infer cost functions. 
\commentty{need to discuss the usage scenario 
of in-house profiling, e.g., what kinds of inputs are used.}
\commentlh{addressed}


The in-house version of \Tool uses RMS as input metric and BB
as cost metric.
It is configured by enabling
only the two instrumentation optimization methods (i.e.,
optimizing instrumentation sites) presented 
in the production-run version, without enabling any approximation. 
This is because we wish 
to obtain more accurate results.
Similar to Aprof~\cite{Aprof1,Aprof2}, 
the in-house version of \Tool leverages several global data structures
to preprocess memory access information to lower memory and disk overhead,
instead of directly tracing read and write information into log, 
as what we did for the production-run version. 
To keep the implementation simple, 
we choose function as profiling granularity.
Otherwise, we need to implement more complex 
mechanisms to judge whether a given code construct 
has finished its execution.  

Different from the production-run version, the in-house version of \Tool 
considers each individual dynamic instance of a function 
as a distinct point during inferring cost function, 
while not merging all dynamic instances of the function 
from the same program run.
This is because if we want to merge all dynamic instances for a given function, 
we need to track accessed memory cells by previous dynamic instances, 
which will incur a large memory overhead. 
As we discussed in Section~\ref{sec:back}, 
given a complexity problem with polynomial complexity 
(e.g. Figure~\ref{fig:mysql27287}),  
the polynomial complexity can be inferred when profiling 
the function containing the outer loop by the in-house version.

The main advantage of the in-house version of \Tool 
over existing profilers (e.g., Aprof~\cite{Aprof1,Aprof2}) is that 
\Tool provides a ranked list of functions to
help localizing complexity problems while 
existing tools simply attribute complexity to each executed function, 
without providing any postmortem analysis. 


%The in-house version of \Tool shares similar 
%design philosophy with Aprof~\cite{Aprof1,Aprof2}.
%Aprof is implemented under Valgrind framework~\cite{valgrind} .
%We will first discuss how we collect RMS and BB under LLVM 
%framework~\cite{llvm} in Section~\ref{sec:inhouse_impl}.
%Aprof simply attributes complexity to each executed function, 
%without providing any postmortem analysis. 
%We will then present how we rank identified super-linear 
%functions in Section~\ref{sec:rank}. 


