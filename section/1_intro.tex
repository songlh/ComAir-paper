\section{Introduction}
\label{sec:intro}

%\subsection{Motivation}
%\label{sec:motiv}

As a type of software bug, performance problems~\footnote{We will use performance problems,
performance issues,  and performance bugs exchangeably,
following previous works in this area~\cite{SongOOPSLA2014,ldoctor}.}
are one major source of software's slowness and inefficiency~\cite{PerfBug,perf.fse10,SongOOPSLA2014,ldoctor,Alabama}. 
%Performance problems cannot be optimized away by state-of-the-art compiler optimizations, 
Performance problems widely exist in production-run software, leading to
poor user experience and  even economic loss in the field~\cite{PerfBug,SongOOPSLA2014,ldoctor}. 
Several highly-publicized failures have already been caused by performance problems,
such as making a website costing millions of dollars useless~\cite{ACA-health}.
Therefore, combating performance problems is urgent.


Many performance bugs are caused by algorithmic inefficiency,
such as implementing a linear algorithm in an $O(N^2)$ way, 
which cannot be optimized away by state-of-the-art 
compiler optimizations. 
We refer to these performance problems as \emph{complexity problems}  in this paper. 
Our empirical study on a representative performance-bug
benchmark set~\cite{PerfBug,SongOOPSLA2014} shows that
nearly half of the user-perceived performance problems that
\emph{occurred in production environment} are complexity problems.
In addition, complexity problems are usually ranked as high-priority bugs in 
software development.  For example, Mozilla developers will immediately try to fix 
complexity bugs degrading exponentially~\cite{mozilla35294}.
\commentty{Was this bug marked as high-priority? Or, we could say ``it took only ? days/hours
to respond"? }
\commentlh{In the cited bug report, one developer asked what is the performance impact 
for the reported bug. He gave out several options. If any is true, he would fix the bug soon. 
One option is ``degrades exponentially with the number of lines'' }


Given the above discussion, addressing complexity problems in
software production runs is an important aspect of fighting performance bugs. 
One commonly used method to diagnose complexity problems
is through algorithmic profiling~\cite{Aprof1,Aprof2,AlgoProf},
which collects profiles from multiple
executions of the same program and attributes complexity to different code constructs, 
such as a loop or a function, in the form of a \textit{cost} function of \textit{input} size.
Therefore, algorithmic profiling can potentially be used to detect complexity problems and
pinpoint the root causes for performance failures caused by complexity problems. 


\input{section/fig_mysql27287}


One MySQL complexity problem is shown in Figure~\ref{fig:mysql27287}.
The loop searches parent \texttt{XML\_NODE} for function parameter \texttt{nitems},
%which presents an array index for another \texttt{XML\_NODE}.
which is used as an array index. 
All \texttt{XML\_NODE}s are maintained in the array \texttt{items}.
The loop iterates through the array \texttt{items}
backwardly and searches for the first \texttt{XML\_NODE} 
\commentlh{with \texttt{level} one less than the \texttt{XML\_NODE} indexed by \texttt{nitems}?} (Lines 7--11).
This piece of code looks innocent.
However, there is an outer loop not shown in the figure.
The outer loop will keep calling \texttt{xml\_parent\_tag} using
the next sibling of the previous \texttt{XML\_NODE},
which has $O(N^2)$ complexity in terms of the number of children of a parent \texttt{XML\_NODE}.
Developers may think that using an implementation with $O(N^2)$ complexity is fine,
since an \texttt{XML\_NODE} usually does not have too many children.
However, during performance failure runs,
an \texttt{XML\_NODE} contains tens of thousands of children,
and this leads significant showdown perceived by the end users.
\commentty{To make the example more readable, can we add ``+", ``-" to indicate
where the bug was and how it was fixed? }
\commentlh{I will address this later.}

To fix this bug, the developers added an extra field to each \texttt{XML\_NODE} to save its parent,
and this field is initialized when an \texttt{XML\_NODE} is created.
After applying this patch, the code shown in Figure~\ref{fig:mysql27287} was completely removed.
However, it took developers around 5 months to figure this
out.\footnote{We count the time from when developers confirmed this is performance bug
to when the patch was submitted.}
Production-run algorithmic profiling 
can point out the complexity of this piece of code is $O(N^2)$, 
which is exactly the root cause, 
and can also provide workload information 
to confirm the necessity to fix this bug.


%There has been some research on designing algorithmic profiling 
%to diagnose performance issues~\cite{gprof,oprofile}. 
%However, these techniques
Existing techniques
are not capable of handling production-run complexity problems
efficiently and effectively due to several reasons. 
First, many algorithmic profilers~\cite{Aprof1,Aprof2,AlgoProf} and performance 
testing tools~\cite{Alabama,PerfBlower} are designed for in-house usage and cannot be 
deployed in production runs due to heavy overhead. 
Recent techniques on algorithmic 
profiling~\cite{Aprof1,Aprof2,AlgoProf} will incur more than $30\times$ runtime overhead.
Second, in-house profilers often {\color{red} provide} limited knowledge of real-world workload, which is necessary 
to determine if a complexity problem can cause user-perceived performance 
impact. A previous empirical study shows that workload keeps changing and 
developers usually do not have a good understanding of real-world workload~\citep{PerfBug}.  
Third, existing profilers intended for production usage~\cite{gprof,oprofile,LagHunter,IntroPerf}
can measure only how much time 
is spent in each code construct during one single run,
but fail to synthesize information from multiple runs
or provide any indication about how the execution time scales.


\noindent\textbf{Contributions.}
\label{sec:con}
%
The goal of our research is two fold. First, we want to better 
understand  complexity problems, including 
their root causes, how user-perceived performance impact 
in production environment is generated,
their characterization \commentlh{characteristics? I am not sure}, 
and how the bugs in each category are
fixed.  Toward this end, 
we conduct an empirical on a representative
performance-bug benchmark suite \cite{PerfBug,SongOOPSLA2014},
containing 65 user-perceived  performance bugs from five
real-world applications.  We discovered that 
1) around three-fourths of the studied complexity problems are
caused by repeated executions of a loop or a recursive function;
2) for most complexity problems,
the users describe how to change the input size to reproduce the scaling problem during reporting;
and 3) complexity problems usually take a longer time to diagnose and fix,
and more effective tool supports are needed. \commentlh{We need another one to replace 3). 
Hypothesis testing shows that there is no significant difference.}
To the best of our knowledge, our work is the first study focusing on complexity problems.
%Our findings and implications can motivate future research on complexity problems.
%They have already guided our selection of design points when building the in-house version of \Tool,
%and inspired us to apply sampling to the production-run version of \Tool.



Second, guided by the findings from the empirical
study, we develop \Tool, the first automated tool to effectively and efficiently 
conduct algorithmic profiling  under production-run setting.
Given a program under profiling, \Tool first instruments the program
using a light-weighted instrumentation method. 
The key idea is to use software-based sampling to conduct algorithmic profiling.
Given a code construct with multiple dynamic instances in a program run,
we sample some of the dynamic instances and leverage the mark-and-recapture
method \citep{mark-recapture} to infer information for all instances.
\commentty{Not sure I am right...} \commentlh{It is right.}
\Tool then collects runtime profiles as the program is running
in production environment with different inputs.
\commentty{Better define what inputs are...}
Next, \Tool synthesizes the profiles and generates a cost function of input size
for each code construct to describe its complexity. 
\commentty{Any novel ideas in this step?}
Finally, \Tool  reports a ranked list of code constructs in terms of their likelihood
of containing performance bugs due to complexity problems. \commentty{We may need to define code
constructs.} 
\commentlh{We don't have ranking list for production-run setting, and we only have it under in-house setting.}


%{\color{red} TODO: discuss the ranking list}

\Tool provides several benefits over existing performance profilers:
1) \Tool supports production-run algorithmic profiling by taking into account
real-world workload and can thus discover most of the real complexity problems;
2) \Tool considers multiple runtime profiles and automatically synthesizes them
into a cost function for each code construct; 
\commentlh{we may need to remove this one, 
since existing techniques can also provide this functionality.}
3) \Tool incurs negligible runtime overhead while achieving accurate profiling results;
4) \Tool  simplifies the task of detecting performance bugs related to complexity
problems by providing a ranked lists of code constructs in terms of their
cost functions; 
5) \commentty{what else?} \commentlh{provide information about real-world workloads 
and improve developers' understanding?}




We envision that \Tool can be used in at least two scenarios. 
First, \Tool can be deployed on user end to conduct production-run performance
profiling. The results (i.e., a ranked list of code constructs with their cost functions)
are returned to developers, which can help to localize performance 
bugs and understand 
which code constructs have the most performance impact on the system.
Second, \Tool can be configured as an in-house testing tools used by 
developers and testers. \commentty{how to make it as a testing tool.}
\commentlh{something like generating performance testing oracle?}
Third, ... \commentty{more usage scenarios?}


To evaluate \Tool, we apply the approach to ? popular benchmarks and real-world 
C/C++ programs with both known and previously unknown complexity 
problems.  Our results show that  \Tool effectively identifies complexity
problems.  Within \Tool, we show that 
sampling allows us to significantly lower the runtime overhead.
Specifically, \Tool  lowered the runtime overhead to less than
$5\%$ for $34$ out of $38$ benchmarks,
without sacrificing the profiling capability and the profiling latency.
The evaluation also shows that sampling does not hurt the profiling capability
and does not require to profile more program runs,
not increasing profiling latency, since
the majority of complexity problems are caused by
repeated executions of a loop or a recursive function, as shown by our empirical study.
Compared to ... \commentty{Need to update the this paragraph based 
on the results.}


In summary, we make the following contributions:

\begin{itemize}

\item We conduct the first empirical study on real-world complexity problems.
The study provides several important findings and implications that can
help developers better understand complexity problems and design tools
to handle them. 


\if 0
\item We design and implement the in-house version of \Tool through
thoroughly investigating different design points during algorithmic profiling.
Our experimental results show that \Tool can effectively analyze performance failures
caused by different types of complexity problems and attribute complexity information accurately.

\fi

\item We develop   \Tool, the first performance profiling tool that is intended to be used
in production environment to effectively detect performance
issues caused by different types of complexity problems and attribute the 
problems to specific code constructs with negligible
overhead.  
\Tool can also be configured as an in-house testing tool. 

\item We implement \Tool and conduct an empirical study to demonstrate 
its effectiveness and efficiency in detecting complexity problems. 



\end{itemize}
