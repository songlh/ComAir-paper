\section{Online Algorithmic Profiling}
\label{sec:online}

In this section, we present technical details 
for the production-run version of \Tool, 
including the high-level design choices
and several optimization policies. 

We envision \Tool to be used in the following way 
under the production-run setting.
Given a monitored program, \Tool creates multiple versions of it, 
and for each version \Tool only instruments a small piece of code. 
All different versions are distributed to different end users. 
Since there is a huge amount of end users, 
we anticipate that enough profiles can still be collected 
for each version 
to conduct algorithmic profiling. 
 
\subsection{High-level Design}
\label{sec:high}

We design the production-run version 
of \Tool following three principles. 

First, \textit{study-guided design}.
We leverage our empirical study results 
to select profiling targets and suitable input metrics.
As discussed in Section~\ref{sec:back}, 
all complexity problems are 
caused either by a loop or a recursive function. 
Therefore, the production-run version of \Tool chooses loops 
and recursive functions as profiling targets, 
and it instruments distinct loops or recursive functions to create multiple
versions of a monitored program. 
Another important finding of our study
is that the most two commonly involved 
data structures in complexity problems 
are array and linked list.
Therefore, if a loop is to process an array 
or a linked list, we use DSS as its input metric.
Otherwise, we use RMS. 
Intuitively, DSS requires to record less dynamic information, 
and replacing RMS with DSS whenever it is possible 
can lower runtime overhead. 

Second, \textit{approximation}.
Accurately recording dynamic information for input and cost metrics
may incur a large runtime overhead.
Therefore, we propose two approximation mechanisms. 
First, if a loop is to process an array, 
we only record the addresses for the first 
and last accessed elements.
We calculate the difference between the two addresses, 
and use it as DSS.
Second, instead of using executed BBs, 
we use LIs as cost metric for loops 
and use RIs for recursive functions. 

Third, \textit{sampling}.
Previous works~\cite{liblit03,liblit05,CCI,SongOOPSLA2014,ldoctor}
demonstrate that sampling can greatly 
reduce overhead for dynamic techniques,
while still preserving their desired 
detection and diagnosis capability. 
These previous work motivate us to apply sampling to algorithmic profiling. 
Our study in Section~\ref{sec:back} shows that 
the majority of complexity problems are caused by repeated execution of a loop
or a recursive function. 
This result inspires us to sample some execution of 
a loop or a recursive function,
and infer information for all execution, 
based on collected samples.

\subsection{Detailed Implementation}











\subsection{Technical Design}
As we discussed in Section~\ref{sec:study}, 
the majority of complexity problems studied are caused 
by repeated executions of a loop or a recursive function. 
Previous works show that sampling code constructs that are executed 
multiple times in one program run can lower the runtime overhead, 
while still being able to collect enough runtime information 
without hurting diagnosis latency\cite{SongOOPSLA2014,ldoctor}. 
Inspired by our study and the earlier works, 
we apply sampling to efficiently profile loops 
and recursive functions with multiple executions. 

\noindent\textbf{Input Metric}
If the specified code construct is an array-processing loop 
or a linked-list-processing loop,
we will use DSS as the input metric. 
Otherwise, we will use RMS+ as the input metric. 

As we discussed in Section~\ref{sec:inhouse}, 
there are two methods, top-down and bottom-up, 
to analyze RMS+ and DSS records collected 
for multiple dynamic instances of a code construct in one program run. 
We leverage the top-down method for the in-house version of \Tool. 
However, the top-down method is not suitable for sampling. 
The reason is as follows.
Assume we have a code construct \texttt{c} to monitor. 
It is inside a loop \texttt{l} and is executed multiple times in one program run.
There are fewer dynamic instances of \texttt{l}
than dynamic instances of \texttt{c}.
If we apply the top-down method, 
we need to sample dynamic instances of \texttt{l}, 
and it is very likely that we will miss these instances. 
For each dynamic instance of \texttt{l}, 
there will be more computation, 
compared with an instance of \texttt{c}.
More overhead will be incurred to collect 
information for dynamic instances of \texttt{l}.
Therefore, we apply the bottom-up method 
in the production-run version of \Tool.
We sample instances of \texttt{c} to record 
distinct memory cells contributing RMS+ 
or distinct elements in an array or a linked list.
We use the sampled information to infer RMS+ 
or DSS for all instances of \texttt{c} in one program run.


The sampling method is similar to that described in previous works on statistical 
debugging\cite{liblit03,liblit05,CCI,SongOOPSLA2014,ldoctor}.
We make a cloned version of the monitored code construct.
We instrument the cloned version to record information for RMS+ or DSS. 
We dump the recorded information to log 
whenever the cloned version finishes execution. 
We add extra delimiters to log to differentiate information collected from different instances.
Before each execution of the monitored code construct, 
we choose between the cloned version and the original version. 
How many times the cloned version is executed 
depends on a tunable sampling rate. 
To make the choice between the two versions,
we add a global counter to the monitored program. 
If the counter value is larger than $0$, 
we choose the original version and decrease the counter value by $1$.
If the counter value is equal to $0$,
we choose the cloned version and reset the counter value to 
a random number, 
whose expectation is equal to the inverse of the sampling rate.  


We leverage the mark-and-recapture method\citep{mark-recapture} to 
estimate RMS+ or DSS for all dynamic instances of a code construct 
based on the collected samples. 
Mark-and-recapture is a commonly used statistical method 
for estimating the size of an animal population. 
In this method, some of the animals are captured, marked, and released. 
Then, another group of the animials are captured.
The size of the whole animal population is estimated 
based on the ratio of marked animals in the second captured sample.  


Each sample of a monitored code construct is a set of memory cells, 
which contribute RMS+ or represent distinct elements in an array or a linked list. 
In one program run, we assume that we collect a sequence of $m$ samples. 
Given the $i$th sample, $M_i$ represents the 
total number of distinct memory cells in the previous $i-1$ samples, 
$C_i$ represents the number of distinct memory cells in the $i$th sample,
and $R_i$ represents the number of distinct memory cells in 
the $i$th sample that also appeared in one of the previous $i-1$ samples.
The total number of distinct memory cells for all dynamic instances 
of the monitored code construct can be estimated as:


%\begin{equation} \label{eq:mark}
%$$p_v(S_v(a)) = 1 - \prod\limits_{u \in S_v(a)}(1 - p_{u,v})$$
%N = \frac{\sum\limits_{i=1}^m M_i*C_i}{\sum\limits_{i=1}^m R_i}
%\end{equation}

\begin{equation} \label{eq:mark}
N = \sum\limits_{i=1}^m M_i*C_i\Big/\sum\limits_{i=1}^m R_i
\end{equation}

\noindent\textbf{Cost Metric}
The production-run version of \Tool focuses on recursive functions or loops.
If the monitored code construct is a recursive function,
we use RIs as the cost metric.
If the monitored code construct is a loop, 
we use LIs as the cost metric. 
We do not apply sampling when collecting these two metrics. 
As we discussed in Section~\ref{sec:inhouse},
these two metrics will incur a smaller overhead compared with BBs, 
and they can still provide accurate profiling results.  


\subsection{Implementation}

{\color{red} Todo: How to implement RMS and DSS}

\subsection{Static Optimizations}

\noindent{\color{red} Todo: How to efficiently count BB}

\noindent{\color{red} Todo: The optimization for array}

\noindent{\color{red} Todo: more loop-invariant address outside of the loop}

\noindent{\color{red} Todo: remove unnecessary read/write instrumentation}









